{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Yuliana Alejandra Molina Cortés\n",
        "\n",
        "#Code without libraries"
      ],
      "metadata": {
        "id": "4aphO59NYhgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# loaddata\n",
        "path = '/content/Indicadores_municipales_sabana_DA (3).csv'\n",
        "data = pd.read_csv(path, sep=\",\", encoding='ISO-8859-1')\n",
        "data = data.fillna(data.mean(numeric_only=True))\n",
        "data['Drenaje_Categoria'] = pd.cut(data['porc_vivsndren10'], bins=[0, 20, 40, 60, 80, 100], labels=[1, 2, 3, 4, 5])\n",
        "data.dropna(subset=['Drenaje_Categoria'], inplace=True)\n",
        "\n",
        "#---------\n",
        "# convertir de categoricas a numericas a las columnas 'gdo_rezsoc00', 'gdo_rezsoc05', y 'gdo_rezsoc10'\n",
        "# diccionario de mapeo para cada columna\n",
        "#mapeo_columna_00 = {'Alto': 0, 'Muy alto': 1}\n",
        "#mapeo_columna_05 = {'Alto': 0, 'Medio': 1, 'Muy alto': 2, 'Bajo': 3}\n",
        "#mapeo_columna_10 = {'Alto': 0, 'Muy alto': 1, 'Medio': 2}\n",
        "\n",
        "# Aplica el mapeo a cada columna respectiva\n",
        "#data['gdo_rezsoc00'] = data['gdo_rezsoc00'].map(mapeo_columna_00)\n",
        "#data['gdo_rezsoc05'] = data['gdo_rezsoc05'].map(mapeo_columna_05)\n",
        "#data['gdo_rezsoc10'] = data['gdo_rezsoc10'].map(mapeo_columna_10)\n",
        "\n",
        "#-----------------\n",
        "# Extract features and target\n",
        "#categorical columns 'gdo_rezsoc00', 'gdo_rezsoc05', 'gdo_rezsoc10',\n",
        "X = data[['pobtot_ajustada', 'pobreza', 'pobreza_e', 'pobreza_m', 'vul_car', 'vul_ing', 'npnv', 'ic_rezedu', 'ic_asalud', 'ic_segsoc', 'ic_cv', 'ic_sbv', 'ic_ali', 'carencias', 'carencias3', 'plb', 'plb_m', 'rankin_p', 'rankin_pe', 'N_pobreza', 'N_pobreza_e', 'N_pobreza_m', 'N_vul_car', 'N_vul_ing', 'N_npnv', 'N_ic_rezedu', 'N_ic_asalud', 'N_ic_segsoc', 'N_ic_cv', 'N_ic_sbv', 'N_ic_ali', 'N_carencias', 'N_carencias3', 'N_plb', 'N_plb_m', 'perrankin_p', 'perrankin_pe', 'cppobreza', 'cppobreza_e', 'cppobreza_m', 'cpvul_car', 'cpic_rezedu', 'cpic_asalud', 'cpic_segsoc', 'cpic_cv', 'cpic_sbv', 'cpic_ali', 'cpcarencias', 'cpcarencias3', 'cpplb', 'cpplbm', 'pobtot_00', 'pobtot_05', 'pobtot_10', 'porc_pob_15_analfa00', 'porc_pob_15_analfa05', 'porc_pob_15_analfa10', 'porc_pob614_noasiste00', 'porc_pob614_noasiste05', 'porc_pob614_noasiste10', 'porc_pob15_basicainc00', 'porc_pob15_basicainc05', 'porc_pob15_basicainc10', 'porc_pob_snservsal00', 'porc_pob_snservsal05', 'porc_pob_snservsal10', 'porc_vivpisotierra00', 'porc_vivpisotierra05', 'porc_vivpisotierra10', 'porc_vivsnsan00', 'porc_vivsnsan05', 'porc_vivsnsan10', 'porc_snaguaent00', 'porc_snaguaent05', 'porc_snaguaent10', 'porc_vivsndren00', 'porc_vivsndren05', 'porc_vivsndren10', 'porc_vivsnenergia00', 'porc_vivsnenergia05', 'porc_vivsnenergia10', 'porc_vivsnlavadora00', 'porc_vivsnlavadora05', 'porc_vivsnlavadora10', 'porc_vivsnrefri00', 'porc_vivsnrefri05', 'porc_vivsnrefr10', 'irez_soc00', 'irez_soc05', 'irez_soc10', 'l_ocupnac00', 'l_ocupnac05', 'l_ocupnac10', 'p_rez_edu_90', 'p_rez_edu_00', 'p_rez_edu_10', 'p_ser_sal_00', 'p_ser_sal_10', 'p_viv_pisos_90', 'p_viv_pisos_00', 'p_viv_pisos_10', 'p_viv_muros_90', 'p_viv_muros_00', 'p_viv_muros_10', 'p_viv_techos_90', 'p_viv_techos_00', 'p_viv_techos_10', 'p_viv_hacin_90', 'p_viv_hacin_00', 'p_viv_hacin_10', 'p_viv_agu_entub_90', 'p_viv_agu_entub_00', 'p_viv_agu_entub_10', 'p_viv_dren_90', 'p_viv_dren_00', 'p_viv_dren_000', 'p_viv_elect_90', 'p_viv_elect_00', 'p_viv_elect_10', 'pobreza_alim_90', 'pobreza_alim_00', 'pobreza_alim_10', 'pobreza_cap_90', 'pobreza_cap_00', 'pobreza_cap_10', 'pobreza_patrim_90', 'pobreza_patrim_00', 'pobreza_patrim_10', 'gini_90', 'gini_00', 'gini_10']]\n",
        "y = data['Drenaje_Categoria']\n",
        "\n",
        "# Split the data into training and testing sets (80/20)\n",
        "def manual_train_test_split(X, y, test_size):\n",
        "    num_samples = len(X)\n",
        "    split_index = int(num_samples * (1 - test_size))\n",
        "    X_train, X_test = X[:split_index], X[split_index:]\n",
        "    y_train, y_test = y[:split_index], y[split_index:]\n",
        "    return X_train, X_test, y_train, y_test\n",
        "#Dividir datos en train y test 80/20\n",
        "test_size = 0.2\n",
        "X_train, X_test, y_train, y_test = manual_train_test_split(X.to_numpy(), y.to_numpy(), test_size)\n",
        "\n",
        "# Standardize the features (important for KNN)\n",
        "mean = X_train.mean(axis=0)\n",
        "std = X_train.std(axis=0)\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n",
        "\n",
        "# KNN--------------------------------------------------\n",
        "def manual_knn(X_train, y_train, X_test, k):\n",
        "    y_pred = []\n",
        "    for test_point in X_test:\n",
        "        distances = np.linalg.norm(X_train - test_point, axis=1)\n",
        "        nearest_indices = np.argsort(distances)[:k]\n",
        "        nearest_labels = y_train[nearest_indices]\n",
        "        prediction = np.bincount(nearest_labels).argmax()\n",
        "        y_pred.append(prediction)\n",
        "    return np.array(y_pred)\n",
        "\n",
        "k = 4  # number of neighbors as needed\n",
        "y_pred_knn = manual_knn(X_train, y_train, X_test, k)\n",
        "\n",
        "# Calculate the accuracy of KNN\n",
        "correct_knn = (y_pred_knn == y_test).sum()\n",
        "accuracy_knn = correct_knn / len(y_test)\n",
        "print(\"Precision of KNN model:\", accuracy_knn)\n",
        "#print(y_pred_knn)\n",
        "\n",
        "# Perceptron\n",
        "def manual_perceptron(X_train, y_train, X_test, learning_rate, epochs):\n",
        "    num_samples, num_features = X_train.shape\n",
        "    weights = np.zeros(num_features)\n",
        "    bias = 0\n",
        "    for _ in range(epochs):\n",
        "        for i in range(num_samples):\n",
        "            activation = np.dot(X_train[i], weights) + bias\n",
        "            if y_train[i] * activation <= 0:\n",
        "                weights += learning_rate * y_train[i] * X_train[i]\n",
        "                bias += learning_rate * y_train[i]\n",
        "    y_pred = np.sign(np.dot(X_test, weights) + bias)\n",
        "    return y_pred\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "y_pred_perceptron = manual_perceptron(X_train, y_train, X_test, learning_rate, epochs)\n",
        "\n",
        "# Calculate the accuracy of the Perceptron\n",
        "correct_perceptron = (y_pred_perceptron == y_test).sum()\n",
        "accuracy_perceptron = correct_perceptron / len(y_test)\n",
        "print(\"Precision of Perceptron model:\", accuracy_perceptron)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd00f4b-833b-46a6-a3c0-f51081150061",
        "id": "ihv6onyEvNDN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-e1f007862354>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['Drenaje_Categoria'] = pd.cut(data['porc_vivsndren10'], bins=[0, 20, 40, 60, 80, 100], labels=[1, 2, 3, 4, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision of KNN model: 0.6843177189409368\n",
            "Precision of Perceptron model: 0.5478615071283096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code with libraries"
      ],
      "metadata": {
        "id": "mmgpjFU8yE9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#codigo con librerias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Cargar tus datos\n",
        "path = '/content/Indicadores_municipales_sabana_DA (3).csv'\n",
        "data = pd.read_csv(path, sep=\",\", encoding='ISO-8859-1')\n",
        "#data = data.dropna()\n",
        "data = data.fillna(data.mean(numeric_only=True))\n",
        "# Crear una columna categórica basada en 'porc_vivsndren10'\n",
        "data['Drenaje_Categoria'] = pd.cut(data['porc_vivsndren10'], bins=[0, 20, 40, 60, 80, 100], labels=[1, 2, 3, 4, 5])\n",
        "data.dropna(subset=['Drenaje_Categoria'], inplace=True)\n",
        "# Separar las características (X) y el objetivo (y)\n",
        "#X = data[['porc_vivsnenergia10', 'porc_vivsnrefri05', 'pobreza_m']]\n",
        "X = data[['pobtot_ajustada', 'pobreza', 'pobreza_e', 'pobreza_m', 'vul_car', 'vul_ing', 'npnv', 'ic_rezedu', 'ic_asalud', 'ic_segsoc', 'ic_cv', 'ic_sbv', 'ic_ali', 'carencias', 'carencias3', 'plb', 'plb_m', 'rankin_p', 'rankin_pe', 'N_pobreza', 'N_pobreza_e', 'N_pobreza_m', 'N_vul_car', 'N_vul_ing', 'N_npnv', 'N_ic_rezedu', 'N_ic_asalud', 'N_ic_segsoc', 'N_ic_cv', 'N_ic_sbv', 'N_ic_ali', 'N_carencias', 'N_carencias3', 'N_plb', 'N_plb_m', 'perrankin_p', 'perrankin_pe', 'cppobreza', 'cppobreza_e', 'cppobreza_m', 'cpvul_car', 'cpic_rezedu', 'cpic_asalud', 'cpic_segsoc', 'cpic_cv', 'cpic_sbv', 'cpic_ali', 'cpcarencias', 'cpcarencias3', 'cpplb', 'cpplbm', 'pobtot_00', 'pobtot_05', 'pobtot_10', 'porc_pob_15_analfa00', 'porc_pob_15_analfa05', 'porc_pob_15_analfa10', 'porc_pob614_noasiste00', 'porc_pob614_noasiste05', 'porc_pob614_noasiste10', 'porc_pob15_basicainc00', 'porc_pob15_basicainc05', 'porc_pob15_basicainc10', 'porc_pob_snservsal00', 'porc_pob_snservsal05', 'porc_pob_snservsal10', 'porc_vivpisotierra00', 'porc_vivpisotierra05', 'porc_vivpisotierra10', 'porc_vivsnsan00', 'porc_vivsnsan05', 'porc_vivsnsan10', 'porc_snaguaent00', 'porc_snaguaent05', 'porc_snaguaent10', 'porc_vivsndren00', 'porc_vivsndren05', 'porc_vivsndren10', 'porc_vivsnenergia00', 'porc_vivsnenergia05', 'porc_vivsnenergia10', 'porc_vivsnlavadora00', 'porc_vivsnlavadora05', 'porc_vivsnlavadora10', 'porc_vivsnrefri00', 'porc_vivsnrefri05', 'porc_vivsnrefr10', 'irez_soc00', 'irez_soc05', 'irez_soc10', 'l_ocupnac00', 'l_ocupnac05', 'l_ocupnac10', 'p_rez_edu_90', 'p_rez_edu_00', 'p_rez_edu_10', 'p_ser_sal_00', 'p_ser_sal_10', 'p_viv_pisos_90', 'p_viv_pisos_00', 'p_viv_pisos_10', 'p_viv_muros_90', 'p_viv_muros_00', 'p_viv_muros_10', 'p_viv_techos_90', 'p_viv_techos_00', 'p_viv_techos_10', 'p_viv_hacin_90', 'p_viv_hacin_00', 'p_viv_hacin_10', 'p_viv_agu_entub_90', 'p_viv_agu_entub_00', 'p_viv_agu_entub_10', 'p_viv_dren_90', 'p_viv_dren_00', 'p_viv_dren_000', 'p_viv_elect_90', 'p_viv_elect_00', 'p_viv_elect_10', 'pobreza_alim_90', 'pobreza_alim_00', 'pobreza_alim_10', 'pobreza_cap_90', 'pobreza_cap_00', 'pobreza_cap_10', 'pobreza_patrim_90', 'pobreza_patrim_00', 'pobreza_patrim_10', 'gini_90', 'gini_00', 'gini_10']]\n",
        " # Reemplaza 'tus_columnas_de_interes' por las columnas relevantes\n",
        "y = data['Drenaje_Categoria']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba (80 20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (importante para KNN)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# Crear un modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=4)  # Puedes ajustar el valor de 'n_neighbors'\n",
        "\n",
        "# Entrenar el modelo\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Calcular la precisión del modelo\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(\"Precisión del modelo KNN:\", accuracy_knn)\n",
        "#print(y_pred_knn)\n",
        "\n",
        "# Crear un modelo de Perceptrón\n",
        "perceptron = Perceptron(max_iter=100, random_state=42)  # Puedes ajustar los parámetros según sea necesario\n",
        "\n",
        "# Entrenar el modelo\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_perceptron = perceptron.predict(X_test)\n",
        "\n",
        "# Calcular la precisión del modelo\n",
        "accuracy_perceptron = accuracy_score(y_test, y_pred_perceptron)\n",
        "print(\"Precisión del modelo Perceptrón:\", accuracy_perceptron)\n"
      ],
      "metadata": {
        "id": "vejUxpIyZ9lT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f552334-6e6e-4a8b-c15a-28762835357c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-946e2f04089b>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['Drenaje_Categoria'] = pd.cut(data['porc_vivsndren10'], bins=[0, 20, 40, 60, 80, 100], labels=[1, 2, 3, 4, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo KNN: 0.7556008146639511\n",
            "Precisión del modelo Perceptrón: 0.6863543788187373\n"
          ]
        }
      ]
    }
  ]
}